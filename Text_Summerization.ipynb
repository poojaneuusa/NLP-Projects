{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe/Ak6CptLpOJ172ZjtdS8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojaneuusa/NLP-Projects/blob/main/Text_Summerization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lexrank"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsyJ0iihUqYh",
        "outputId": "b8d92123-24e9-4460-c6c4-d34fdf81fb7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lexrank\n",
            "  Downloading lexrank-0.1.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from lexrank) (1.26.4)\n",
            "Collecting path.py>=10.5 (from lexrank)\n",
            "  Downloading path.py-12.5.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pyrsistent>=0.14.0 (from lexrank)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: regex>=2017.11.9 in /usr/local/lib/python3.10/dist-packages (from lexrank) (2024.11.6)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from lexrank) (1.13.1)\n",
            "Collecting urlextract>=0.7 (from lexrank)\n",
            "  Downloading urlextract-1.9.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting path (from path.py>=10.5->lexrank)\n",
            "  Downloading path-17.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from urlextract>=0.7->lexrank) (3.10)\n",
            "Collecting uritools (from urlextract>=0.7->lexrank)\n",
            "  Downloading uritools-4.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from urlextract>=0.7->lexrank) (4.3.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from urlextract>=0.7->lexrank) (3.16.1)\n",
            "Downloading lexrank-0.1.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urlextract-1.9.0-py3-none-any.whl (21 kB)\n",
            "Downloading path-17.1.0-py3-none-any.whl (23 kB)\n",
            "Downloading uritools-4.0.3-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: uritools, pyrsistent, path, urlextract, path.py, lexrank\n",
            "Successfully installed lexrank-0.1.0 path-17.1.0 path.py-12.5.0 pyrsistent-0.20.0 uritools-4.0.3 urlextract-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install networkx\n",
        "\n",
        "import networkx as nx\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Document to summarize\n",
        "document = \"\"\"\n",
        "Immediately after the verdict, in a statement released through her spokesperson, Amber had said she was ‘sad’ she had ‘lost the case’. The jury had also found Johnny guilty of defamation on one count and ordered him to pay Amber $2 million in damages. However, most legal experts said the case had been vindication for Johnny.\n",
        "Speaking about it on Today Show, Amber said about the jury, “I don’t blame them. I actually understand. He’s a beloved character and people feel they know him. He’s a fantastic actor.”\n",
        "The actor also addressed the memes that have been made about her and the hate coming her way on social media through the trial. She said, “I don’t care what one thinks about me or what judgments you want to make about what happened in the privacy of my own home, in my marriage, behind closed doors. I don’t presume the average person should know those things. And so I don’t take it personally. But even somebody who is sure I’m deserving of all this hate and vitriol, even if you think that I’m lying, you still couldn’t look me in the eye and tell me that you think on social media there’s been a fair representation. You cannot tell me that you think that this has been fair.”\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize document into sentences\n",
        "sentences = nltk.sent_tokenize(document)\n",
        "print(f\"Number of sentences: {len(sentences)}\")\n",
        "\n",
        "# Compute embeddings for sentences\n",
        "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cos_scores = util.cos_sim(embeddings, embeddings).cpu().numpy()\n",
        "\n",
        "# Use NetworkX to create a graph and calculate centrality\n",
        "G = nx.Graph()\n",
        "for i in range(len(cos_scores)):\n",
        "    for j in range(i + 1, len(cos_scores)):\n",
        "        if cos_scores[i, j] > 0.5:  # Threshold for edge creation\n",
        "            G.add_edge(i, j, weight=cos_scores[i, j])\n",
        "\n",
        "# Compute degree centrality\n",
        "centrality = nx.degree_centrality(G)\n",
        "\n",
        "# Get the indices of the most central sentences\n",
        "most_central_indices = sorted(centrality, key=centrality.get, reverse=True)[:3]\n",
        "\n",
        "# Print the top 3 most central sentences\n",
        "print(\"\\nMost central sentences:\")\n",
        "for idx in most_central_indices:\n",
        "    print(sentences[idx].strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pfvUCA1X48O",
        "outputId": "057b6664-d05c-4ac2-eb50-7eff582ff302"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 12\n",
            "\n",
            "Most central sentences:\n",
            "The jury had also found Johnny guilty of defamation on one count and ordered him to pay Amber $2 million in damages.\n",
            "Immediately after the verdict, in a statement released through her spokesperson, Amber had said she was ‘sad’ she had ‘lost the case’.\n",
            "Speaking about it on Today Show, Amber said about the jury, “I don’t blame them.\n"
          ]
        }
      ]
    }
  ]
}